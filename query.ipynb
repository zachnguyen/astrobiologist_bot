{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zachn\\anaconda3\\envs\\qa_bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, TypedDict\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from get_embedding_function import get_embedding_function\n",
    "import os, json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "CHROMA_PATH = \"chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=get_embedding_function()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.get(include=[])['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(\n",
    "        collection_name=\"podcast\",\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(open('prompts/answer_query.md').read())\n",
    "\n",
    "model = ChatAnthropic(model='claude-3-5-sonnet-20240620')\n",
    "\n",
    "chain_with_prompt = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': None,\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get(include=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Who is Lee Cronin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QueryResponse:\n",
    "    query_text: str\n",
    "    response_text: str\n",
    "    sources: List[str]\n",
    "\n",
    "def query_rag(query_text: str) -> QueryResponse:\n",
    "\n",
    "    class AgentState(TypedDict):\n",
    "        question: str\n",
    "        raw_docs: list[BaseMessage]\n",
    "        formatted_docs: list[str]\n",
    "        generation: str\n",
    "        sources: list[str]\n",
    "\n",
    "    def get_docs(state: AgentState):\n",
    "        #print(\"get_docs:\", state)\n",
    "        question = state[\"question\"]\n",
    "        docs = retriever.invoke(question)\n",
    "        state[\"sources\"] = [doc.metadata.get(\"id\") for doc in docs]\n",
    "        state[\"raw_docs\"] = docs\n",
    "        return state\n",
    "    \n",
    "    def format_docs(state:AgentState):\n",
    "        #print(\"format_docs:\",state)\n",
    "        documents = state[\"raw_docs\"]\n",
    "        state[\"formatted_docs\"] = \"\\n\\n---\\n\\n\".join([\"Talk Title:\" + doc.metadata.get(\"vid_title\", None) \n",
    "                                    + \"\\nExcerpt:\" + doc.page_content + \"\\nPublished time:\" + doc.response_metadata.get(\"published_dt\", None)\n",
    "                                    for doc in documents])\n",
    "        return state\n",
    "    \n",
    "    def generate(state:AgentState):\n",
    "        #print(\"generate:\", state)\n",
    "        question = state[\"question\"]\n",
    "        formatted_docs = state[\"formatted_docs\"]\n",
    "        result = chain_with_prompt.invoke({\"question\": question, \"context\":formatted_docs})\n",
    "        state[\"generation\"] = result\n",
    "        return state\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node(\"get_docs\", get_docs)\n",
    "    workflow.add_node(\"format_docs\", format_docs)\n",
    "    workflow.add_node(\"generate\", generate)\n",
    "    workflow.add_edge(\"get_docs\", \"format_docs\")\n",
    "    workflow.add_edge(\"format_docs\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "    workflow.set_entry_point(\"get_docs\")\n",
    "\n",
    "    rag_app = workflow.compile()\n",
    "\n",
    "    result = rag_app.invoke({\"question\":query_text})\n",
    "\n",
    "    print(f\"Response: {result['generation']}\\nSources: {result['sources']}\")\n",
    "\n",
    "    return QueryResponse(\n",
    "        query_text=query_text, response_text=result['generation'], sources=result['sources']\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I apologize, but I do not have any context or information provided about Sara Walker or assembly theory from the given prompt. There are no excerpts, episode titles, or other details given that I could use to formulate a response about this topic. Without any relevant information to draw from, I cannot accurately answer the question or elaborate on Sara Walker's views about assembly theory. If you could provide some specific context or information about this topic, I would be happy to try answering the question based on that. My apologies that I cannot be more helpful with the limited information available.\n",
      "Sources: []\n",
      "I apologize, but I do not have any context or information provided about Sara Walker or assembly theory from the given prompt. There are no excerpts, episode titles, or other details given that I could use to formulate a response about this topic. Without any relevant information to draw from, I cannot accurately answer the question or elaborate on Sara Walker's views about assembly theory. If you could provide some specific context or information about this topic, I would be happy to try answering the question based on that. My apologies that I cannot be more helpful with the limited information available.\n"
     ]
    }
   ],
   "source": [
    "response = query_rag(\"What did Sara Walker say about assembly theory?\")\n",
    "print(response.response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
